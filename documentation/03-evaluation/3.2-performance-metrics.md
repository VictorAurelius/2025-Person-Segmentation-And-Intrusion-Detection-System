# Các Chỉ Số Đánh Giá

## 1. Tổng Quan

Hệ thống được đánh giá qua 3 nhóm metrics chính: Detection Quality, Performance, và System Reliability.

---

## 2. Detection Quality Metrics

### A. Confusion Matrix

```
                  Predicted
              Positive  Negative
Actual  Pos     TP        FN
        Neg     FP        TN
```

**Definitions:**
- **True Positive (TP)**: Phát hiện đúng intrusion
- **False Positive (FP)**: Phát hiện nhầm (false alarm)
- **False Negative (FN)**: Bỏ sót intrusion
- **True Negative (TN)**: Đúng không có intrusion

### B. Precision

```python
Precision = TP / (TP + FP)
```

**Ý nghĩa:** Tỷ lệ alerts chính xác

**Ví dụ:**
```
TP = 95 detections
FP = 5 false alarms
Precision = 95 / (95 + 5) = 95%
```

**Đánh giá:**
- >95%: Excellent
- 85-95%: Good
- 70-85%: Acceptable
- <70%: Poor

### C. Recall (Sensitivity)

```python
Recall = TP / (TP + FN)
```

**Ý nghĩa:** Tỷ lệ intrusions được phát hiện

**Ví dụ:**
```
TP = 95 detections
FN = 5 missed intrusions
Recall = 95 / (95 + 5) = 95%
```

**Đánh giá:**
- >95%: Excellent
- 85-95%: Good
- 70-85%: Acceptable
- <70%: Poor

### D. F1-Score

```python
F1 = 2 * (Precision * Recall) / (Precision + Recall)
```

**Ý nghĩa:** Harmonic mean của Precision và Recall

**Ví dụ:**
```
Precision = 95%
Recall = 95%
F1 = 2 * (0.95 * 0.95) / (0.95 + 0.95) = 95%
```

**Đánh giá:**
- >90%: Excellent
- 80-90%: Good
- 65-80%: Acceptable
- <65%: Poor

### E. Specificity

```python
Specificity = TN / (TN + FP)
```

**Ý nghĩa:** Tỷ lệ không có intrusion được xác định đúng

---

## 3. Performance Metrics

### A. Frames Per Second (FPS)

```python
FPS = Total Frames / Total Time
```

**Measurement:**
```python
import time

start = time.time()
frame_count = 0

while processing:
    process_frame()
    frame_count += 1

end = time.time()
fps = frame_count / (end - start)
```

**Standards:**
- Real-time: >25 FPS
- Acceptable: 15-25 FPS
- Slow: <15 FPS

### B. Processing Time per Frame

```python
avg_time = total_processing_time / total_frames
```

**Breakdown:**
```
Motion Detection:    15ms (40%)
Morphology:          8ms  (20%)
Contour Detection:   7ms  (18%)
Intrusion Check:     5ms  (13%)
Drawing/Display:     3ms  (8%)
Total:              38ms  (100%)
```

**Target:** <40ms per frame (25 FPS)

### C. Latency

```python
latency = time_detected - time_occurred
```

**Measurement:**
```python
frame_timestamp = frame_number / video_fps
detection_timestamp = time.time()
latency = detection_timestamp - frame_timestamp
```

**Requirements:**
- Critical alerts: <200ms
- Normal alerts: <500ms
- Batch processing: <1000ms

### D. Memory Usage

```python
import psutil

process = psutil.Process()
memory_mb = process.memory_info().rss / 1024 / 1024
```

**Tracking:**
```
Initial: 150 MB
After 1 hour: 180 MB
After 24 hours: 200 MB
Memory leak rate: ~2 MB/hour
```

**Thresholds:**
- Low: <200 MB
- Medium: 200-500 MB
- High: >500 MB

### E. CPU Usage

```python
cpu_percent = psutil.cpu_percent(interval=1)
```

**Per Module:**
```
Motion Detection: 35%
Image Processing: 25%
Contour Analysis: 15%
Alert System: 5%
Overhead: 20%
Total: 100% of available CPU
```

---

## 4. Accuracy Metrics

### A. Intersection over Union (IoU)

```python
def calculate_iou(box1, box2):
    x1 = max(box1[0], box2[0])
    y1 = max(box1[1], box2[1])
    x2 = min(box1[2], box2[2])
    y2 = min(box1[3], box2[3])

    intersection = max(0, x2 - x1) * max(0, y2 - y1)
    area1 = (box1[2] - box1[0]) * (box1[3] - box1[1])
    area2 = (box2[2] - box2[0]) * (box2[3] - box2[1])
    union = area1 + area2 - intersection

    return intersection / union
```

**Usage:** So sánh detected bounding box với ground truth

**Thresholds:**
- IoU > 0.7: Good match
- IoU 0.5-0.7: Acceptable
- IoU < 0.5: Poor match

### B. Detection Accuracy by Object Size

```python
# Small objects (< 1% frame)
small_objects_accuracy = TP_small / (TP_small + FN_small)

# Medium objects (1-5% frame)
medium_objects_accuracy = TP_medium / (TP_medium + FN_medium)

# Large objects (> 5% frame)
large_objects_accuracy = TP_large / (TP_large + FN_large)
```

**Expected:**
- Large: >95%
- Medium: >85%
- Small: >70%

### C. Temporal Consistency

```python
def temporal_consistency(detections):
    """Measure stability of detections over time"""
    gaps = []
    for i in range(len(detections) - 1):
        if detections[i]['object_id'] == detections[i+1]['object_id']:
            gap = detections[i+1]['frame'] - detections[i]['frame']
            gaps.append(gap)

    avg_gap = np.mean(gaps)
    return 1.0 / avg_gap  # Lower gap = higher consistency
```

---

## 5. System Reliability Metrics

### A. Uptime

```python
uptime_percent = (total_time - downtime) / total_time * 100
```

**Target:** >99.5% uptime

### B. Mean Time Between Failures (MTBF)

```python
MTBF = total_operating_time / number_of_failures
```

**Example:**
```
Operating time: 720 hours (30 days)
Failures: 2
MTBF = 720 / 2 = 360 hours
```

**Target:** >500 hours

### C. Mean Time To Recovery (MTTR)

```python
MTTR = total_recovery_time / number_of_failures
```

**Example:**
```
Failure 1: 5 minutes to restart
Failure 2: 3 minutes to restart
MTTR = (5 + 3) / 2 = 4 minutes
```

**Target:** <10 minutes

### D. Error Rate

```python
error_rate = errors / total_frames_processed
```

**Categories:**
- Critical errors (crashes): 0%
- Processing errors: <0.1%
- Warning messages: <1%

---

## 6. Alert Quality Metrics

### A. Alert Precision

```python
alert_precision = valid_alerts / total_alerts
```

**Target:** >90%

### B. Alert Response Time

```python
response_time = alert_triggered_time - intrusion_start_time
```

**Components:**
1. Detection time: <200ms
2. Validation time: <300ms
3. Alert generation: <100ms
**Total:** <600ms

### C. Alert Cooldown Effectiveness

```python
duplicate_rate = duplicate_alerts / total_alerts
```

**Target:** <5% duplicate alerts

---

## 7. Comparative Metrics

### A. Method Comparison

| Method | Precision | Recall | F1 | FPS |
|--------|-----------|--------|-----|-----|
| MOG2 | 92% | 90% | 91% | 28 |
| KNN | 90% | 93% | 91.5% | 22 |
| FrameDiff | 85% | 88% | 86.5% | 35 |

### B. Configuration Comparison

| Config | Day | Night | Variable Light |
|--------|-----|-------|----------------|
| Default | 91% | 65% | 78% |
| Optimized | 93% | 78% | 85% |

---

## 8. Metric Collection

### A. Automated Logging

```python
class MetricsCollector:
    def __init__(self):
        self.metrics = {
            'frames_processed': 0,
            'true_positives': 0,
            'false_positives': 0,
            'false_negatives': 0,
            'processing_times': [],
            'memory_samples': []
        }

    def log_detection(self, is_intrusion, is_correct):
        self.metrics['frames_processed'] += 1
        if is_intrusion and is_correct:
            self.metrics['true_positives'] += 1
        elif is_intrusion and not is_correct:
            self.metrics['false_positives'] += 1
        elif not is_intrusion and not is_correct:
            self.metrics['false_negatives'] += 1

    def calculate_metrics(self):
        tp = self.metrics['true_positives']
        fp = self.metrics['false_positives']
        fn = self.metrics['false_negatives']

        precision = tp / (tp + fp) if (tp + fp) > 0 else 0
        recall = tp / (tp + fn) if (tp + fn) > 0 else 0
        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0

        return {
            'precision': precision,
            'recall': recall,
            'f1_score': f1,
            'avg_processing_time': np.mean(self.metrics['processing_times'])
        }
```

### B. Real-time Dashboard

```python
def display_metrics(metrics):
    """Display real-time metrics on frame"""
    text = [
        f"FPS: {metrics['fps']:.1f}",
        f"Precision: {metrics['precision']:.2%}",
        f"Recall: {metrics['recall']:.2%}",
        f"Alerts: {metrics['total_alerts']}"
    ]

    y_offset = 30
    for line in text:
        cv2.putText(frame, line, (10, y_offset),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
        y_offset += 30
```

---

## 9. Benchmark Standards

### Industry Standards

```yaml
# PETS Dataset Benchmark
minimum_detection_rate: 0.85
maximum_false_alarm_rate: 0.15

# VIRAT Dataset Benchmark
precision_threshold: 0.80
recall_threshold: 0.85
```

### Project-Specific Goals

```yaml
# Easy scenarios (daylight, clean background)
target_precision: 0.95
target_recall: 0.95
target_fps: 25

# Medium scenarios (indoor, multiple objects)
target_precision: 0.85
target_recall: 0.85
target_fps: 20

# Hard scenarios (night, weather)
target_precision: 0.70
target_recall: 0.75
target_fps: 15
```

---

## 10. Report Generation

### A. Summary Report

```python
def generate_summary_report(metrics):
    report = f"""
    ================================
    INTRUSION DETECTION SYSTEM
    PERFORMANCE REPORT
    ================================

    Detection Quality:
    - Precision:    {metrics['precision']:.2%}
    - Recall:       {metrics['recall']:.2%}
    - F1-Score:     {metrics['f1_score']:.2%}

    Performance:
    - Average FPS:  {metrics['fps']:.1f}
    - Latency:      {metrics['latency']:.0f}ms

    Reliability:
    - Uptime:       {metrics['uptime']:.2%}
    - Error Rate:   {metrics['error_rate']:.4%}

    Total Statistics:
    - Frames:       {metrics['total_frames']:,}
    - Intrusions:   {metrics['total_intrusions']}
    - Alerts:       {metrics['total_alerts']}
    """
    return report
```

### B. Detailed CSV Export

```python
import csv

def export_detailed_metrics(metrics, filename):
    with open(filename, 'w', newline='') as f:
        writer = csv.writer(f)
        writer.writerow(['Timestamp', 'Frame', 'Detection', 'Processing Time', 'Memory'])

        for record in metrics['detailed_records']:
            writer.writerow([
                record['timestamp'],
                record['frame_number'],
                record['detection_result'],
                record['processing_time'],
                record['memory_usage']
            ])
```

---

**Ngày tạo**: Tháng 1/2025
